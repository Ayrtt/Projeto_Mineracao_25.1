{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8249624,"sourceType":"datasetVersion","datasetId":4890913}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:02:39.069497Z","iopub.execute_input":"2025-05-23T00:02:39.069865Z","iopub.status.idle":"2025-05-23T00:02:39.474467Z","shell.execute_reply.started":"2025-05-23T00:02:39.069836Z","shell.execute_reply":"2025-05-23T00:02:39.473275Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## --- Funções ---","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\n\n\ndef kfolds(X, y, folds): #Divide os dados em folds para validação cruzada estratificada.\n    \n    X_train_list = []\n    X_test_list = []\n    y_train_list = []\n    y_test_list = []\n\n    # Garante que X e y são arrays numpy para indexação\n    X_np = np.array(X)\n    y_np = np.array(y)\n\n    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n    for train_index, test_index in kf.split(X_np, y_np):\n        X_train_list.append(X_np[train_index])\n        X_test_list.append(X_np[test_index])\n        y_train_list.append(y_np[train_index])\n        y_test_list.append(y_np[test_index])\n\n    return X_train_list, X_test_list, y_train_list, y_test_list\n\ndef normalize_numerical(X, numerical_cols): #Normaliza apenas as colunas numéricas especificadas usando MinMaxScaler.\n\n    X_normalized = X.copy()\n    scaler = MinMaxScaler()\n    X_normalized[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n    return X_normalized\n\ndef rfe(X_processed, y, max_iter, features_to_select): \n    # Realiza a seleção de features usando Recursive Feature Elimination(RFE)\n    # com Regressão Logística.\n\n    modeloRFE = LogisticRegression(max_iter=max_iter, solver='liblinear', random_state=42)\n    rfe_selector = RFE(modeloRFE, n_features_to_select=features_to_select)\n    fitRFE = rfe_selector.fit(X_processed, y)\n    selected_features = X_processed.columns[fitRFE.support_]\n    return X_processed[selected_features]\n\ndef specificity_score(y_true, y_pred): # Calcula a especificidade (True Negative Rate).\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    if (tn + fp) == 0:\n        return 0.0\n    return tn / (tn + fp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:02:54.991622Z","iopub.execute_input":"2025-05-23T00:02:54.991950Z","iopub.status.idle":"2025-05-23T00:02:56.260483Z","shell.execute_reply.started":"2025-05-23T00:02:54.991926Z","shell.execute_reply":"2025-05-23T00:02:56.259498Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## --- Carregamento e Pré-processamento dos Dados ---","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/aids-virus-infection-prediction/AIDS_Classification_15000.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:02:42.260896Z","iopub.execute_input":"2025-05-23T00:02:42.261477Z","iopub.status.idle":"2025-05-23T00:02:42.342514Z","shell.execute_reply.started":"2025-05-23T00:02:42.261444Z","shell.execute_reply":"2025-05-23T00:02:42.341356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:53:54.965622Z","iopub.execute_input":"2025-05-22T20:53:54.966114Z","iopub.status.idle":"2025-05-22T20:53:54.980273Z","shell.execute_reply.started":"2025-05-22T20:53:54.966081Z","shell.execute_reply":"2025-05-22T20:53:54.979083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:54:23.103339Z","iopub.execute_input":"2025-05-22T20:54:23.103628Z","iopub.status.idle":"2025-05-22T20:54:23.186047Z","shell.execute_reply.started":"2025-05-22T20:54:23.103608Z","shell.execute_reply":"2025-05-22T20:54:23.185047Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## --- Gráficos ---","metadata":{}},{"cell_type":"markdown","source":"### Distribuição das Variáveis Numéricas (Histogramas e Box Plots):\n\nObjetivo: Entender a distribuição de cada feature numérica. Histogramas mostram a forma da distribuição (normal, assimétrica, etc.), enquanto Box Plots são excelentes para identificar outliers e a dispersão dos dados.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nnumerical_cols = ['time', 'age', 'wtkg', 'karnof', 'preanti', 'cd40', 'cd420', 'cd80', 'cd820']\nplt.figure(figsize=(15, 10))\nfor i, col in enumerate(numerical_cols):\n    plt.subplot(3, 3, i + 1)\n    sns.histplot(dataset[col], kde=True)\n    plt.title(f'Distribuição de {col}')\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(15, 10))\nfor i, col in enumerate(numerical_cols):\n    plt.subplot(3, 3, i + 1)\n    sns.boxplot(y=dataset[col])\n    plt.title(f'Box Plot de {col}')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:43:42.624372Z","iopub.execute_input":"2025-05-22T20:43:42.625157Z","iopub.status.idle":"2025-05-22T20:43:48.078225Z","shell.execute_reply.started":"2025-05-22T20:43:42.625126Z","shell.execute_reply":"2025-05-22T20:43:48.077169Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Relação entre Features Numéricas e Target (Box Plots ou Violin Plots):\n\nObjetivo: Visualizar se a distribuição de uma feature numérica difere significativamente entre as classes infected e not infected.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nfor i, col in enumerate(numerical_cols):\n    plt.subplot(3, 3, i + 1)\n    sns.boxplot(x='infected', y=col, data=dataset, palette='pastel')\n    plt.title(f'Distribuição de {col} por Status de Infecção')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:02.999572Z","iopub.execute_input":"2025-05-22T20:44:03.000620Z","iopub.status.idle":"2025-05-22T20:44:04.666635Z","shell.execute_reply.started":"2025-05-22T20:44:03.000569Z","shell.execute_reply":"2025-05-22T20:44:04.665317Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Matriz de Correlação (Heatmap):\n\nObjetivo: Visualizar a correlação entre todas as features numéricas. Isso pode ajudar a identificar features redundantes ou importantes.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 10))\ncorr_matrix = dataset[numerical_cols].corr()\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Matriz de Correlação das Features Numéricas')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:20.816904Z","iopub.execute_input":"2025-05-22T20:44:20.817215Z","iopub.status.idle":"2025-05-22T20:44:21.272511Z","shell.execute_reply.started":"2025-05-22T20:44:20.817195Z","shell.execute_reply":"2025-05-22T20:44:21.271572Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Contagem de Classes da Variável Alvo (infected):\n\nObjetivo: Verificar o balanceamento da classe alvo. Como você já identificou um desbalanceamento, esta visualização confirmará a proporção.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nsns.countplot(x='infected', data=dataset)\nplt.title('Contagem de Casos Infectados vs. Não Infectados')\nplt.xlabel('Status de Infecção (0: Não Infectado, 1: Infectado)')\nplt.ylabel('Número de Casos')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:46.153071Z","iopub.execute_input":"2025-05-22T20:44:46.153376Z","iopub.status.idle":"2025-05-22T20:44:46.303011Z","shell.execute_reply.started":"2025-05-22T20:44:46.153356Z","shell.execute_reply":"2025-05-22T20:44:46.302092Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Relação entre Features Categóricas/Binárias e Target (Gráficos de Barras Agrupados):\n\nObjetivo: Entender como cada categoria de uma feature categórica se relaciona com a probabilidade de infecção.","metadata":{}},{"cell_type":"code","source":"categorical_cols = ['trt', 'hemo', 'homo', 'drugs', 'oprior', 'z30', 'race', 'gender', 'str2', 'strat', 'symptom', 'treat', 'offtrt']\nplt.figure(figsize=(20, 15))\nfor i, col in enumerate(categorical_cols):\n    plt.subplot(4, 4, i + 1)\n    sns.countplot(x=col, hue='infected', data=dataset, palette='viridis')\n    plt.title(f'Relação de {col} com Infecção')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:59.270316Z","iopub.execute_input":"2025-05-22T20:44:59.270646Z","iopub.status.idle":"2025-05-22T20:45:01.580798Z","shell.execute_reply.started":"2025-05-22T20:44:59.270620Z","shell.execute_reply":"2025-05-22T20:45:01.579741Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## --- Configuração dos Modelos ---","metadata":{}},{"cell_type":"code","source":"# Importações dos modelos e métricas\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import (BaggingClassifier,\n                              RandomForestClassifier,\n                              GradientBoostingClassifier)\nfrom sklearn.metrics import (accuracy_score,\n                             precision_score,\n                             recall_score,\n                             roc_auc_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:03:20.091751Z","iopub.execute_input":"2025-05-23T00:03:20.092116Z","iopub.status.idle":"2025-05-23T00:03:27.509380Z","shell.execute_reply.started":"2025-05-23T00:03:20.092057Z","shell.execute_reply":"2025-05-23T00:03:27.507954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pré-processamento (one-hot encode categóricas, normaliza numéricas),\n# seleção de features e divisão em folds para validação cruzada.\n\ny = dataset['infected']\nX_raw = dataset.drop(columns=['infected'])\n\n# Identificação das colunas\nnumerical_cols = ['time', 'age', 'wtkg', 'karnof', 'preanti', 'cd40', 'cd420', 'cd80', 'cd820']\ncategorical_nominal_cols = ['trt', 'race', 'strat']\n# As colunas binárias como hemo, homo, drugs, etc., podem ser mantidas como estão\n\n# Aplicar One-Hot Encoding para colunas nominais. drop_first para evitar multicolinearidade\nX_encoded = pd.get_dummies(X_raw, columns=categorical_nominal_cols, drop_first=True)\n\n# Normalizar apenas as colunas numéricas contínuas\nX_normalized = normalize_numerical(X_encoded, numerical_cols)\n\n# Assumindo que você quer 8 features selecionadas e max_iter=1000 para RFE\n# RFE será aplicado sobre o DataFrame já com one-hot encoding e normalização seletiva\nX_final = rfe(X_normalized, y, 1000, 8)\n\nfolds = 5 # Número de folds fixo, pode ser parametrizado se necessário\n\nX_train, X_test, y_train, y_test = kfolds(X_final, y, folds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:03:02.601730Z","iopub.execute_input":"2025-05-23T00:03:02.602269Z","iopub.status.idle":"2025-05-23T00:03:03.421673Z","shell.execute_reply.started":"2025-05-23T00:03:02.602241Z","shell.execute_reply":"2025-05-23T00:03:03.420542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dicionário para armazenar as instâncias de cada modelo com seus nomes\nmodels_to_evaluate = {\n    \"DecisionTree_Default\": DecisionTreeClassifier(random_state=42),\n    \"SVC_Default\": SVC(probability=True, random_state=42),\n    \"KNeighbors_Default\": KNeighborsClassifier(),\n    \"BaggingClassifier\": BaggingClassifier(random_state=42),\n    \"RandomForestClassifier\": RandomForestClassifier(random_state=42),\n    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=42),\n    \"XGBoostClassifier\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n    \"LightGBMClassifier\": lgb.LGBMClassifier(random_state=42),\n    \"DecisionTree_Entropy\": DecisionTreeClassifier(criterion='entropy', random_state=0),\n    \"SVC_Linear\": SVC(kernel='linear', probability=True, random_state=42),\n    \"KNeighbors_N6_Auto\": KNeighborsClassifier(n_neighbors=6, algorithm='auto'),\n    \"DecisionTree_MaxDepth10\": DecisionTreeClassifier(max_depth=10, random_state=0),\n    \"SVC_Poly_Degree5\": SVC(kernel='poly', degree=5, probability=True, random_state=42),\n    \"KNeighbors_N7_BallTree\": KNeighborsClassifier(n_neighbors=7, algorithm='ball_tree')\n}\n\n# Dicionário para armazenar as métricas de todos os modelos em cada fold\nall_model_metrics = {}\nfor model_name in models_to_evaluate.keys():\n    all_model_metrics[model_name] = {\n        'accuracy': [],\n        'precision': [],\n        'recall': [],\n        'specificity': [],\n        'roc_auc_value': [],\n        'y_true_folds': [],  # Armazena os rótulos verdadeiros de cada fold\n        'y_proba_folds': []  # Armazena as probabilidades previstas de cada fold\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:03:32.849328Z","iopub.execute_input":"2025-05-23T00:03:32.850203Z","iopub.status.idle":"2025-05-23T00:03:32.860457Z","shell.execute_reply.started":"2025-05-23T00:03:32.850162Z","shell.execute_reply":"2025-05-23T00:03:32.859153Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## --- Loop de Validação Cruzada ---","metadata":{}},{"cell_type":"code","source":"print(f\"Iniciando validação cruzada com {folds} folds...\")\nfor fold_idx in range(folds):\n    xtrain = X_train[fold_idx]\n    xtest = X_test[fold_idx]\n    ytrain = y_train[fold_idx]\n    ytest = y_test[fold_idx]\n\n    print(f\"\\n--- Fold {fold_idx + 1}/{folds} ---\")\n\n    for model_name, model_instance in models_to_evaluate.items():\n        try:\n            # Para XGBoost, 'scale_pos_weight' precisa ser ajustado por fold\n            if model_name == \"XGBoostClassifier\":\n                neg_count = np.sum(ytrain == 0)\n                pos_count = np.sum(ytrain == 1)\n                model_instance.set_params(scale_pos_weight=neg_count / pos_count)\n\n            # Treinamento do modelo\n            model = model_instance.fit(xtrain, ytrain)\n            result = model.predict(xtest)\n\n            # Cálculo das métricas\n            acc = accuracy_score(ytest, result)\n            prec = precision_score(ytest, result, zero_division=0)\n            rec = recall_score(ytest, result, zero_division=0)\n            spec = specificity_score(ytest, result)\n\n            # Para AUC, precisamos das probabilidades\n            current_fold_auc = np.nan # Inicializa com NaN\n            y_proba = np.array([]) # Inicializa como array vazio\n            if hasattr(model, \"predict_proba\"):\n                try:\n                    y_proba = model.predict_proba(xtest)[:, 1]\n                    current_fold_auc = roc_auc_score(ytest, y_proba)\n                    # Armazena y_true e y_proba para a plotagem da curva ROC combinada\n                    all_model_metrics[model_name]['y_true_folds'].append(ytest)\n                    all_model_metrics[model_name]['y_proba_folds'].append(y_proba)\n                except ValueError as e:\n                    print(f\"  Aviso: Não foi possível calcular AUC para {model_name} no fold {fold_idx + 1} (probabilidades): {e}\")\n                    all_model_metrics[model_name]['y_true_folds'].append(np.array([])) # Adiciona array vazio em caso de erro\n                    all_model_metrics[model_name]['y_proba_folds'].append(np.array([])) # Adiciona array vazio em caso de erro\n            else:\n                print(f\"  Aviso: Modelo {model_name} não suporta predict_proba para AUC.\")\n                all_model_metrics[model_name]['y_true_folds'].append(np.array([])) # Adiciona array vazio se não suportar proba\n                all_model_metrics[model_name]['y_proba_folds'].append(np.array([])) # Adiciona array vazio se não suportar proba\n\n            # Armazenamento das métricas\n            all_model_metrics[model_name]['accuracy'].append(acc)\n            all_model_metrics[model_name]['precision'].append(prec)\n            all_model_metrics[model_name]['recall'].append(rec)\n            all_model_metrics[model_name]['specificity'].append(spec)\n            all_model_metrics[model_name]['roc_auc_value'].append(current_fold_auc)\n\n            # Opcional: Imprimir métricas para cada fold\n            # print(f\"  Modelo: {model_name} - Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, Spec: {spec:.4f}, AUC: {auc_score:.4f}\")\n\n        except Exception as e:\n            print(f\"  Erro ao treinar/avaliar {model_name} no fold {fold_idx + 1}: {e}\")\n            # Adiciona NaN para todas as métricas e arrays vazios para y_true/y_proba em caso de erro\n            for metric_key in ['accuracy', 'precision', 'recall', 'specificity', 'auc']:\n                all_model_metrics[model_name][metric_key].append(np.nan)\n            all_model_metrics[model_name]['y_true_folds'].append(np.array([]))\n            all_model_metrics[model_name]['y_proba_folds'].append(np.array([]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:03:41.418448Z","iopub.execute_input":"2025-05-23T00:03:41.418818Z","iopub.status.idle":"2025-05-23T00:22:04.250529Z","shell.execute_reply.started":"2025-05-23T00:03:41.418793Z","shell.execute_reply":"2025-05-23T00:22:04.249287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## --- Exibição dos Resultados Médios e Desvio Padrão ---","metadata":{}},{"cell_type":"code","source":"print(\"\\n--- Resultados Médios da Validação Cruzada ---\")\nfinal_results = {}\nfor model_name, metrics in all_model_metrics.items():\n    # Filtra NaNs antes de calcular a média e o desvio padrão\n    accuracies_clean = [m for m in metrics['accuracy'] if not np.isnan(m)]\n    precisions_clean = [m for m in metrics['precision'] if not np.isnan(m)]\n    recalls_clean = [m for m in metrics['recall'] if not np.isnan(m)]\n    specificities_clean = [m for m in metrics['specificity'] if not np.isnan(m)]\n    aucs_clean = [m for m in metrics['roc_auc_value'] if not np.isnan(m)]\n\n    avg_accuracy = np.mean(accuracies_clean) if accuracies_clean else np.nan\n    std_accuracy = np.std(accuracies_clean) if accuracies_clean else np.nan\n    avg_precision = np.mean(precisions_clean) if precisions_clean else np.nan\n    avg_recall = np.mean(recalls_clean) if recalls_clean else np.nan\n    avg_specificity = np.mean(specificities_clean) if specificities_clean else np.nan\n    avg_auc = np.mean(aucs_clean) if aucs_clean else np.nan\n\n    final_results[model_name] = {\n        'avg_accuracy': avg_accuracy,\n        'std_accuracy': std_accuracy,\n        'avg_precision': avg_precision,\n        'avg_recall': avg_recall,\n        'avg_specificity': avg_specificity,\n        'avg_auc': avg_auc\n    }\n    print(f\"\\nModelo: {model_name}\")\n    print(f\"  Acurácia Média: {avg_accuracy:.4f} (Desvio Padrão: {std_accuracy:.4f})\")\n    print(f\"  Precisão Média: {avg_precision:.4f}\")\n    print(f\"  Recall Médio: {avg_recall:.4f}\")\n    print(f\"  Especificidade Média: {avg_specificity:.4f}\")\n    print(f\"  AUC Média: {avg_auc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:38:03.488616Z","iopub.execute_input":"2025-05-23T00:38:03.489020Z","iopub.status.idle":"2025-05-23T00:38:03.501934Z","shell.execute_reply.started":"2025-05-23T00:38:03.488983Z","shell.execute_reply":"2025-05-23T00:38:03.500915Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## --- Avaliação e Comparação de Modelos ---\nApós o treinamento, as visualizações são cruciais para comparar o desempenho dos seus diversos modelos.\n\nComparação de Métricas (Gráficos de Barras):","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_curve, auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:40:11.157766Z","iopub.execute_input":"2025-05-23T00:40:11.158189Z","iopub.status.idle":"2025-05-23T00:40:11.455031Z","shell.execute_reply.started":"2025-05-23T00:40:11.158159Z","shell.execute_reply":"2025-05-23T00:40:11.454047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Acurácia\nresults_df = pd.DataFrame.from_dict(final_results, orient='index')\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=results_df.index, y='avg_accuracy', data=results_df, palette='viridis')\nplt.xticks(rotation=45, ha='right')\nplt.ylabel('Acurácia Média')\nplt.title('Acurácia Média dos Modelos')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:40:14.071933Z","iopub.execute_input":"2025-05-23T00:40:14.073029Z","iopub.status.idle":"2025-05-23T00:40:14.660523Z","shell.execute_reply.started":"2025-05-23T00:40:14.072991Z","shell.execute_reply":"2025-05-23T00:40:14.659248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Precision\nresults_df = pd.DataFrame.from_dict(final_results, orient='index')\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=results_df.index, y='avg_precision', data=results_df, palette='viridis')\nplt.xticks(rotation=45, ha='right')\nplt.ylabel('Precisão Média')\nplt.title('Precisão Média dos Modelos')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:40:21.938421Z","iopub.execute_input":"2025-05-23T00:40:21.938776Z","iopub.status.idle":"2025-05-23T00:40:22.280057Z","shell.execute_reply.started":"2025-05-23T00:40:21.938753Z","shell.execute_reply":"2025-05-23T00:40:22.278870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Recall\nresults_df = pd.DataFrame.from_dict(final_results, orient='index')\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=results_df.index, y='avg_recall', data=results_df, palette='viridis')\nplt.xticks(rotation=45, ha='right')\nplt.ylabel('Recall Médio')\nplt.title('Recall Médio dos Modelos')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:40:27.819987Z","iopub.execute_input":"2025-05-23T00:40:27.820374Z","iopub.status.idle":"2025-05-23T00:40:28.143336Z","shell.execute_reply.started":"2025-05-23T00:40:27.820349Z","shell.execute_reply":"2025-05-23T00:40:28.142136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Specificity\nresults_df = pd.DataFrame.from_dict(final_results, orient='index')\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=results_df.index, y='avg_specificity', data=results_df, palette='viridis')\nplt.xticks(rotation=45, ha='right')\nplt.ylabel('Especificidade Média')\nplt.title('Especificidade Média dos Modelos')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:40:35.605954Z","iopub.execute_input":"2025-05-23T00:40:35.606928Z","iopub.status.idle":"2025-05-23T00:40:35.925435Z","shell.execute_reply.started":"2025-05-23T00:40:35.606883Z","shell.execute_reply":"2025-05-23T00:40:35.923899Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Área sob a curva\nresults_df = pd.DataFrame.from_dict(final_results, orient='index')\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=results_df.index, y='avg_auc', data=results_df, palette='viridis')\nplt.xticks(rotation=45, ha='right')\nplt.ylabel('AUC Média')\nplt.title('AUC Média dos Modelos')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:40:42.263780Z","iopub.execute_input":"2025-05-23T00:40:42.264180Z","iopub.status.idle":"2025-05-23T00:40:42.579693Z","shell.execute_reply.started":"2025-05-23T00:40:42.264140Z","shell.execute_reply":"2025-05-23T00:40:42.578421Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Curvas ROC (Receiver Operating Characteristic):\n\nObjetivo: Avaliar a capacidade de um modelo de distinguir entre as classes. A área sob a curva (AUC) é uma métrica importante, e a curva em si mostra o trade-off entre True Positive Rate (Recall) e False Positive Rate.","metadata":{}},{"cell_type":"code","source":"print(\"\\n--- Plotando Curvas ROC Combinadas ---\")\nplt.figure(figsize=(12, 10)) # Define o tamanho da figura\n\nfor model_name, metrics in all_model_metrics.items():\n    # Concatena todos os y_true e y_proba de todos os folds para este modelo\n    # Filtra arrays vazios que podem ter sido adicionados devido a erros ou modelos sem predict_proba\n    y_true_combined = np.concatenate([arr for arr in metrics['y_true_folds'] if arr.size > 0])\n    y_proba_combined = np.concatenate([arr for arr in metrics['y_proba_folds'] if arr.size > 0])\n\n    if y_true_combined.size > 0 and y_proba_combined.size > 0:\n        try:\n            # Calcula a curva ROC\n            fpr, tpr, _ = roc_curve(y_true_combined, y_proba_combined)\n            roc_auc = auc(fpr, tpr)\n            # Plota a curva ROC com o nome do modelo e o valor AUC na legenda\n            plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n        except ValueError as e:\n            print(f\"  Aviso: Não foi possível plotar a curva ROC para {model_name}: {e}\")\n    else:\n        print(f\"  Aviso: Dados insuficientes para plotar a curva ROC para {model_name}.\")\n\n# Plota a linha diagonal de referência (classificador aleatório)\nplt.plot([0, 1], [0, 1], 'k--', label='Classificador Aleatório (AUC = 0.50)')\n\n# Configurações do gráfico\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Taxa de Falso Positivo (FPR)')\nplt.ylabel('Taxa de Verdadeiro Positivo (TPR)')\nplt.title('Curvas ROC Combinadas para Todos os Modelos')\n# Ajusta a posição da legenda para não sobrepor as curvas\nplt.legend(loc=\"lower right\", bbox_to_anchor=(1.25, 0))\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T00:40:48.229140Z","iopub.execute_input":"2025-05-23T00:40:48.229447Z","iopub.status.idle":"2025-05-23T00:40:48.700358Z","shell.execute_reply.started":"2025-05-23T00:40:48.229424Z","shell.execute_reply":"2025-05-23T00:40:48.699129Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Para começar a compreender o AUC, é necessário lembrar que, quanto mais perto de 0,5, mais aleatório. Quanto mais perto de 1, melhor o modelo é em distinguir entre as classes positiva (infectado) e negativa (não infectado).\n\nPortanto, os modelos de melhor desempenho médio foram o GradientBoostingClassifier, LightGBMClassifier, RandomForestClassifier e XGBoostClassifier, nos fazendo perceber que os modelos de boosting foram razoavelmente bem neste dataset.\n\nOs modelos com desempenho médio e baixo (abaixo de 0,65) indicam que talvez não sejam as melhores alternativas para o problema ou que não foram configurados corretamente.\n\nNão realizei tunagem de parâmetros e hiperparâmetros a fundo, então estão muito próximos do padrão.","metadata":{}},{"cell_type":"markdown","source":"## --- Conclusão ---\n\nEste projeto de estatística aplicada teve como objetivo principal desenvolver modelos de Machine Learning capazes de prever o status de infecção por AIDS a partir de dados de pacientes. Através de um pipeline metodológico robusto, que incluiu a análise exploratória de dados, tratamento de features categóricas e numéricas, seleção de features via RFE e uma validação cruzada estratificada em 10 folds, conseguimos avaliar o desempenho de diversos algoritmos de classificação.\n\nOs resultados demonstraram que modelos baseados em ensembles e boosting, como o GradientBoostingClassifier (AUC = 0.70), LightGBMClassifier (AUC = 0.68), RandomForestClassifier (AUC = 0.66) e XGBoostClassifier (AUC = 0.65), foram os que apresentaram o melhor poder discriminatório. Eles superaram significativamente os classificadores mais simples e o desempenho de um classificador aleatório (AUC = 0.50), indicando uma capacidade razoável de distinguir entre pacientes infectados e não infectados. Por outro lado, modelos como a Árvore de Decisão padrão (AUC = 0.55) e o SVC com kernel linear (AUC = 0.50) mostraram desempenho limitado, sugerindo que a complexidade da relação entre as features e o status de infecção não é linear ou não é bem capturada por abordagens mais simplistas.\n\nO sucesso na identificação de modelos com bom poder preditivo, mesmo em um cenário de classes desbalanceadas, valida a importância da abordagem de pré-processamento adotada e da utilização de técnicas como class_weight e scale_pos_weight. Este estudo demonstra a viabilidade de utilizar dados clínicos e demográficos para auxiliar na classificação de pacientes com AIDS, o que pode ter implicações valiosas em pesquisas futuras e na tomada de decisões em saúde pública.","metadata":{}}]}